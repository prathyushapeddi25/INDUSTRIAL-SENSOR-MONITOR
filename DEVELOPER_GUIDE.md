# Industrial Sensor Monitor - Developer Guide

## üéØ What is this Application?

This is a **real-time industrial sensor monitoring system** that simulates, collects, and visualizes data from industrial fermentation equipment. It demonstrates a production-grade data pipeline with anomaly detection, retry mechanisms, and a live dashboard.

---

## üèóÔ∏è System Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Simulator  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> ‚îÇ  Ingestion   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> ‚îÇ   API    ‚îÇ
‚îÇ             ‚îÇ  HTTP   ‚îÇ   Service    ‚îÇ  HTTP   ‚îÇ  Server  ‚îÇ
‚îÇ (generates  ‚îÇ         ‚îÇ (orchestrates‚îÇ         ‚îÇ (FastAPI)‚îÇ
‚îÇ   sensor    ‚îÇ         ‚îÇ  data flow)  ‚îÇ         ‚îÇ          ‚îÇ
‚îÇ   readings) ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                         ‚îÇ
                                                        ‚îÇ
                                                        ‚ñº
                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                            ‚îÇ    Database       ‚îÇ
                                            ‚îÇ   (SQLite)        ‚îÇ
                                            ‚îÇ                   ‚îÇ
                                            ‚îÇ + Anomaly Detect  ‚îÇ
                                            ‚îÇ + Retry Handler   ‚îÇ
                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                        ‚îÇ
                                                        ‚îÇ
                                                        ‚ñº
                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                            ‚îÇ   Dashboard       ‚îÇ
                                            ‚îÇ  (HTML + Chart.js)‚îÇ
                                            ‚îÇ                   ‚îÇ
                                            ‚îÇ  Real-time Graphs ‚îÇ
                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÇ Project Structure

```
industrial-sensor-monitor/
‚îÇ
‚îú‚îÄ‚îÄ backend/                      # Core application logic
‚îÇ   ‚îú‚îÄ‚îÄ simulator.py              # üé≤ Generates fake sensor data
‚îÇ   ‚îú‚îÄ‚îÄ ingestion_service.py      # üîÑ Orchestrates data flow
‚îÇ   ‚îú‚îÄ‚îÄ api.py                    # üåê REST API (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ models.py                 # üíæ Database models (SQLAlchemy)
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py       # üö® Statistical anomaly detection
‚îÇ   ‚îî‚îÄ‚îÄ retry_handler.py          # üîÅ Handles failed operations
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.html            # üìä Real-time visualization
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ start.bat                     # Windows startup script
‚îú‚îÄ‚îÄ start.sh                      # Linux/Mac startup script
‚îî‚îÄ‚îÄ README.md                     # Project overview
```

---

## üîÑ Application Flow (Step by Step)

### **Entry Point: Where Everything Starts**

You start **TWO** separate Python processes:

1. **API Server** (`backend/api.py`) - Port 8000
2. **Ingestion Service** (`backend/ingestion_service.py`)

### **Detailed Flow:**

```
1. API SERVER STARTS (api.py)
   ‚îú‚îÄ> Initializes FastAPI application
   ‚îú‚îÄ> Creates SQLite database (sensor_data.db)
   ‚îú‚îÄ> Initializes AnomalyDetector (statistical analysis)
   ‚îú‚îÄ> Initializes RetryHandler (for reliability)
   ‚îú‚îÄ> Starts listening on http://localhost:8000
   ‚îî‚îÄ> Serves dashboard.html at /dashboard endpoint

2. INGESTION SERVICE STARTS (ingestion_service.py)
   ‚îú‚îÄ> Waits for API to be ready (health check)
   ‚îú‚îÄ> Initializes SensorSimulator
   ‚îî‚îÄ> Enters infinite loop (once per second):
       ‚îÇ
       ‚îú‚îÄ> simulator.py generates 3 readings:
       ‚îÇ   ‚îú‚îÄ> fermenter_temp (35-40¬∞C + noise)
       ‚îÇ   ‚îú‚îÄ> fermenter_ph (6.5-7.5 + noise)
       ‚îÇ   ‚îî‚îÄ> agitator_rpm (300-600 + noise)
       ‚îÇ
       ‚îú‚îÄ> Sends batch HTTP POST to /ingest/batch
       ‚îÇ
       ‚îî‚îÄ> Repeats every 1 second

3. API RECEIVES DATA (/ingest/batch endpoint)
   ‚îú‚îÄ> Validates each measurement:
   ‚îÇ   ‚îú‚îÄ> Check tag is valid
   ‚îÇ   ‚îú‚îÄ> Check value is in range
   ‚îÇ   ‚îî‚îÄ> Parse timestamp
   ‚îÇ
   ‚îú‚îÄ> Anomaly Detection:
   ‚îÇ   ‚îú‚îÄ> Feeds value to AnomalyDetector
   ‚îÇ   ‚îú‚îÄ> Uses rolling window statistics (50 points)
   ‚îÇ   ‚îú‚îÄ> Calculates Z-score (3 std deviations)
   ‚îÇ   ‚îî‚îÄ> Flags if anomalous
   ‚îÇ
   ‚îú‚îÄ> Database Write:
   ‚îÇ   ‚îú‚îÄ> Try to save to SQLite
   ‚îÇ   ‚îú‚îÄ> If fails ‚Üí add to retry queue
   ‚îÇ   ‚îî‚îÄ> RetryHandler retries in background
   ‚îÇ
   ‚îî‚îÄ> Returns success/queued response

4. DASHBOARD DISPLAYS DATA (dashboard.html)
   ‚îú‚îÄ> Loads at http://localhost:8000/dashboard
   ‚îú‚îÄ> Every 2 seconds:
   ‚îÇ   ‚îú‚îÄ> Fetches latest data via GET /data?tag=X
   ‚îÇ   ‚îú‚îÄ> Updates Chart.js graphs
   ‚îÇ   ‚îî‚îÄ> Highlights anomalies in red
   ‚îÇ
   ‚îî‚îÄ> Shows 3 real-time line charts

5. RETRY MECHANISM (retry_handler.py)
   ‚îú‚îÄ> Runs background worker thread
   ‚îú‚îÄ> Periodically checks retry queue
   ‚îú‚îÄ> Attempts to save failed measurements
   ‚îú‚îÄ> If still fails ‚Üí writes to dead letter queue
   ‚îÇ   (failed_measurements.jsonl)
   ‚îî‚îÄ> On startup, recovers from dead letter queue
```

---

## üöÄ How to Start the Application

### **Prerequisites:**
```bash
# You need Python 3.8+ installed
python --version
```

### **Option 1: Use Startup Scripts (Recommended)**

#### **Windows:**
```bash
# Double-click or run:
start.bat
```

This will:
- Install dependencies
- Start API server in new window
- Start ingestion service in new window
- Open dashboard in browser

#### **Linux/Mac:**
```bash
chmod +x start.sh
./start.sh
```

### **Option 2: Manual Start (for Development)**

#### **Step 1: Install Dependencies**
```bash
pip install -r requirements.txt
```

#### **Step 2: Start API Server**
```bash
cd backend
python api.py
```

You should see:
```
Starting Fermenter Monitoring API...
API documentation available at: http://localhost:8000/docs
Dashboard available at: http://localhost:8000/dashboard
INFO:     Uvicorn running on http://0.0.0.0:8000
```

#### **Step 3: Start Ingestion Service (in another terminal)**
```bash
cd backend
python ingestion_service.py
```

You should see:
```
Starting ingestion service (interval: 1s)...
‚úì API is ready
Starting continuous data ingestion (Ctrl+C to stop)...
‚úì Ingested 3 measurements (0 anomalies detected)
‚úì Ingested 3 measurements (1 anomalies detected)
...
```

#### **Step 4: Open Dashboard**
Navigate to: **http://localhost:8000/dashboard**

---

## üìä What to Expect

### **Normal Operation:**

1. **Two console windows running** (API + Ingestion)
2. **Dashboard updates every 2 seconds** with new data points
3. **Three graphs showing:**
   - Fermenter Temperature (35-40¬∞C)
   - Fermenter pH (6.5-7.5)
   - Agitator RPM (300-600)
4. **Anomalies appear as RED dots** on graphs
5. **Console shows ingestion logs** like:
   ```
   ‚úì Ingested 3 measurements (0 anomalies detected)
   ‚úì Ingested 3 measurements (1 anomalies detected)
   ```

### **Database File:**
- A file `sensor_data.db` will be created in the root directory
- Contains all measurements with timestamps and anomaly flags

### **API Documentation:**
- Visit **http://localhost:8000/docs** for interactive API docs
- Try endpoints like:
  - `GET /data?tag=fermenter_temp` - Get temperature data
  - `GET /anomalies?tag=fermenter_ph` - Get pH anomalies
  - `GET /stats` - Get system statistics

---

## üîç Key Components Explained

### **1. simulator.py - Data Generation**
```python
# Generates realistic sensor readings with Gaussian noise
# Also randomly injects anomalies (5% chance)
def generate_reading(self, tag_config):
    value = random.uniform(min_val, max_val)
    noise = random.gauss(0, noise_sigma)
    
    # 5% chance of anomaly
    if random.random() < 0.05:
        value += spike_magnitude
    
    return value
```

**Why it exists:** Simulates real industrial sensors without needing actual hardware.

### **2. ingestion_service.py - Orchestrator**
```python
# Runs simulator and sends data to API
def run(self, interval_seconds=1):
    while True:
        readings = self.simulator.generate_batch()
        self.ingest_readings(readings)  # HTTP POST
        time.sleep(interval_seconds)
```

**Why it exists:** Separates data generation from data storage/processing.

### **3. api.py - REST API**
- **FastAPI framework** for modern, async Python web API
- **Endpoints:**
  - `POST /ingest/batch` - Accept sensor data
  - `GET /data` - Query time-series data
  - `GET /anomalies` - Get flagged anomalies
  - `GET /stats` - System metrics
  - `GET /dashboard` - Serve HTML dashboard

**Why it exists:** Provides a standard interface for data ingestion and retrieval.

### **4. anomaly_detector.py - Statistical Analysis**
```python
# Uses Z-score method (standard deviations from mean)
def analyze_reading(self, tag, value):
    mean = np.mean(window)
    std = np.std(window)
    z_score = abs((value - mean) / std)
    
    return z_score > self.std_threshold  # Default: 3œÉ
```

**Why it exists:** Automatically detects unusual sensor readings that might indicate equipment problems.

### **5. retry_handler.py - Reliability**
```python
# Handles transient failures (network, disk, etc.)
# - Queues failed operations
# - Retries with exponential backoff
# - Persists to dead letter queue if all retries fail
```

**Why it exists:** Ensures no data loss even during temporary system issues.

### **6. models.py - Database Schema**
```python
class Measurement(Base):
    id = Column(Integer, primary_key=True)
    timestamp = Column(DateTime, nullable=False)
    tag = Column(String(50), nullable=False)
    value = Column(Float, nullable=False)
    is_anomaly = Column(Boolean, default=False)
```

**Why it exists:** Defines how data is stored in the database.

### **7. dashboard.html - Visualization**
- Uses **Chart.js** for real-time graphs
- Polls API every 2 seconds
- Color-codes anomalies
- Shows last 100 data points per tag

**Why it exists:** Provides human-readable, real-time monitoring interface.

---

## üéì Learning Path for New Developers

### **Day 1: Understand the Flow**
1. Start the application
2. Watch the console logs
3. Open the dashboard and observe data
4. Look at the database file (use SQLite browser)

### **Day 2: Explore the Code**
1. Read `simulator.py` - simplest component
2. Read `ingestion_service.py` - orchestration
3. Read `api.py` - REST endpoints
4. Open `http://localhost:8000/docs` - interactive API

### **Day 3: Make Changes**
1. Change sensor ranges in `simulator.py`
2. Adjust anomaly threshold in `anomaly_detector.py`
3. Add a new sensor tag
4. Modify dashboard colors

### **Day 4: Understand Reliability**
1. Read `retry_handler.py`
2. Simulate a failure (delete database while running)
3. Watch retry mechanism kick in
4. Inspect `failed_measurements.jsonl`

---

## üêõ Troubleshooting

### **Problem: Port 8000 already in use**
```bash
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:8000 | xargs kill -9
```

### **Problem: Dashboard not loading**
- Check API server is running
- Visit http://localhost:8000/health
- Check browser console for errors

### **Problem: No data appearing**
- Check ingestion service is running
- Check for errors in ingestion service console
- Verify API health: `curl http://localhost:8000/health`

---

## üìö Technologies Used

| Technology | Purpose |
|------------|---------|
| **Python 3.11** | Programming language |
| **FastAPI** | Modern web framework |
| **SQLAlchemy** | ORM for database |
| **SQLite** | Lightweight database |
| **NumPy** | Statistical calculations |
| **Chart.js** | Frontend graphing |
| **Uvicorn** | ASGI server |

---

## üéØ Next Steps

After understanding the flow, you can:

1. **Add new sensor types** (e.g., pressure, flow rate)
2. **Implement alerts** (email/SMS when anomalies detected)
3. **Add authentication** to API endpoints
4. **Export data** to CSV or cloud storage
5. **Improve anomaly detection** with ML models
6. **Add unit tests** for components
7. **Containerize** with Docker
8. **Deploy** to cloud (AWS, Azure, GCP)

---

## üí° Key Concepts Demonstrated

‚úÖ **Microservices pattern** (separate services)  
‚úÖ **REST API design** (standard HTTP endpoints)  
‚úÖ **Real-time data streaming** (continuous ingestion)  
‚úÖ **Anomaly detection** (statistical methods)  
‚úÖ **Retry/resilience patterns** (handling failures)  
‚úÖ **Time-series data** (timestamp-based storage)  
‚úÖ **Separation of concerns** (modular architecture)  

---

## ‚ùì Common Questions

**Q: Why two separate processes?**  
A: Simulates real-world where data sources (sensors) are separate from the backend system.

**Q: Can I use a different database?**  
A: Yes! Change the connection string in `api.py` to PostgreSQL, MySQL, etc.

**Q: Is this production-ready?**  
A: It's a learning project. For production, add: authentication, monitoring, load balancing, proper logging, and tests.

**Q: How do I stop the application?**  
A: Press `Ctrl+C` in both terminal windows or close them.

---

## ü§ù Need Help?

1. Check the logs in console windows
2. Visit API docs: http://localhost:8000/docs
3. Inspect database: Use DB Browser for SQLite
4. Read the code comments - they explain each function

Happy coding! üöÄ
